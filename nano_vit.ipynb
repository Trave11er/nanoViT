{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nanoGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchsummary import summary\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = Path(\"input.txt\")\n",
    "if not file.exists():\n",
    "    # We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
    "    !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "\n",
    "with open(file, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(text[:100])\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "VOCAB_SIZE = len(chars)\n",
    "\n",
    "print(VOCAB_SIZE)\n",
    "\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "print(encode(\"hii there\"))\n",
    "print(decode(encode(\"hii there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "\n",
    "all_data = torch.tensor(encode(text))\n",
    "n = int(0.9*len(all_data)) # first 90% will be train, rest val\n",
    "train_data = all_data[:n]\n",
    "val_data = all_data[n:]\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "CONTEXT_SIZE, BATCH_SIZE = 9, 4\n",
    "\n",
    "def get_batch(data):\n",
    "    ix = torch.randint(len(data) - CONTEXT_SIZE, (BATCH_SIZE,))\n",
    "    x = torch.stack([data[i:i + CONTEXT_SIZE] for i in ix])\n",
    "    y = torch.stack([data[i + 1:i + CONTEXT_SIZE + 1] for i in ix])\n",
    "    return x.to(device), y.to(device)\n",
    "\n",
    "xb, yb = get_batch(train_data)\n",
    "\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(yb.shape)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arch\n",
    "CONTEXT_SIZE = 64 # what is the maximum context length for predictions?\n",
    "N_EMBD = 128\n",
    "NUM_HEADS = 4\n",
    "NUM_BLOCKS = 4\n",
    "DROPOUT = 0.0\n",
    "\n",
    "# training\n",
    "BATCH_SIZE = 64 # how many independent sequences will we process in parallel?\n",
    "MAX_ITERS = 2000\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY = 0.1\n",
    "LEARNING_RATE_DECAY = 0.9\n",
    "\n",
    "\n",
    "class AttentionHead(nn.Module):  # Head\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "    def __init__(self, head_size, is_decoder):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(N_EMBD, head_size, bias=False)\n",
    "        self.query = nn.Linear(N_EMBD, head_size, bias=False)\n",
    "        self.value = nn.Linear(N_EMBD, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(CONTEXT_SIZE, CONTEXT_SIZE)))\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "        self._is_decoder = is_decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)   # B T C\n",
    "        q = self.query(x)  # B T C\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        if self._is_decoder:  # only in decoder blocks\n",
    "            wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # B T C\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "    def __init__(self, head_size, is_decoder=True):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([AttentionHead(head_size, is_decoder) for _ in range(NUM_HEADS)])\n",
    "        self.proj = nn.Linear(head_size * NUM_HEADS, N_EMBD)\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MLP(nn.Module):  # FeedForward\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(N_EMBD, 4 * N_EMBD),\n",
    "            nn.ReLU(),  # ViT paper uses GELU\n",
    "            nn.Linear(4 * N_EMBD, N_EMBD),\n",
    "            nn.Dropout(DROPOUT),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):  # Block\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, is_decoder=True):\n",
    "        # N_EMBD: embedding dimension, NUM_HEADS: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = N_EMBD // NUM_HEADS\n",
    "        self.mha = MultiHeadAttention(head_size, is_decoder)\n",
    "        self.mlp = MLP()\n",
    "        self.ln1 = nn.LayerNorm(N_EMBD)\n",
    "        self.ln2 = nn.LayerNorm(N_EMBD)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # cf eqn 2, 3 of ViT paper\n",
    "        x = x + self.mha(self.ln1(x))\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class SimpleDecoder(nn.Module):  # BigramLangModel\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._token_embed = nn.Embedding(VOCAB_SIZE, N_EMBD)\n",
    "        self._posn_embed = nn.Embedding(CONTEXT_SIZE, N_EMBD)\n",
    "        self.blocks = nn.Sequential(*[TransformerBlock() for _ in range(NUM_BLOCKS)])\n",
    "        self.ln_f = nn.LayerNorm(N_EMBD) # final layer norm\n",
    "        self._lm_head = nn.Linear(N_EMBD, VOCAB_SIZE)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        B, T = x.shape\n",
    "        x = x.long().to(device)\n",
    "        token_embed = self._token_embed(x) # B T C\n",
    "        posn_embed = self._posn_embed(torch.arange(T, device=device))  # T C\n",
    "        x = token_embed + posn_embed  # B T C\n",
    "        # cf eqn 4 of ViT paper\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self._lm_head(x)  # B T VOCAB_SIZE\n",
    "\n",
    "        loss = None\n",
    "        if y is not None:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            y = y.view(B*T)\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, x, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):  # how many tokens ahead to predict\n",
    "            x_cond = x[:, -CONTEXT_SIZE:]\n",
    "            logits, _ = self(x_cond)\n",
    "            last_logits = logits[:, -1, :]  # this is where we only use the last token\n",
    "            last_probs = F.softmax(last_logits, dim=-1)\n",
    "            last_picked_probs = torch.multinomial(last_probs, num_samples=1)\n",
    "            x = torch.concat((x, last_picked_probs), axis=1)\n",
    "        return x\n",
    "\n",
    "model = SimpleDecoder()\n",
    "model.to(device)\n",
    "\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(model.generate(x = context, max_new_tokens=100)[0].tolist()))\n",
    "\n",
    "summary(model, (8,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=LEARNING_RATE_DECAY)\n",
    "start_t = time()\n",
    "\n",
    "for steps in range(MAX_ITERS): # increase number of steps for good results...\n",
    "    if not train:\n",
    "        break\n",
    "    if steps % 100 == 0:\n",
    "        scheduler.step()\n",
    "        print(steps)\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch(train_data)\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "if train:\n",
    "    torch.save(model.state_dict(), f\"foo.torch\")\n",
    "state_dict = torch.load(\"foo.torch\")\n",
    "model.load_state_dict(state_dict)\n",
    "print(f\"Took {round(time() - start_t)}s\")\n",
    "\n",
    "# inference\n",
    "context = torch.zeros((1, 8), dtype=torch.long, device=device)\n",
    "#context = torch.tensor([encode(\"Merry Christmas\")], dtype=torch.long).to(device)\n",
    "print(decode(model.generate(context, max_new_tokens=500)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nanoViT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # mean and std of mnist data\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# visualize\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "def imshow(img):\n",
    "    img = img * 0.3081 + 0.1307  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(npimg, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(10, 2))\n",
    "for i in range(5):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(images[i][0])\n",
    "    ax.set_title(f'Label: {labels[i].item()}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arch\n",
    "PATCH_SIZE = 7  # mnist imgs are 28x28\n",
    "assert 28 % PATCH_SIZE == 0\n",
    "NUM_PATCHES = (28 // PATCH_SIZE)**2  # cf CONTEXT_SIZE\n",
    "CHANNELS = 1\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._conv2d = nn.Conv2d(in_channels=CHANNELS, out_channels=N_EMBD, kernel_size=PATCH_SIZE,\n",
    "                        stride=PATCH_SIZE, padding=0)\n",
    "\n",
    "        self._flatten = nn.Flatten(start_dim=2, end_dim=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._conv2d(x)\n",
    "        x = self._flatten(x)\n",
    "        return x.permute(0, 2, 1) # B C T -> B T C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect shapes\n",
    "print(images.shape)\n",
    "\n",
    "pl = PatchEmbedding()\n",
    "out = pl(images)\n",
    "print(out.shape)\n",
    "\n",
    "# cf eqn 1 of ViT paper\n",
    "class_token = nn.Parameter(torch.ones(BATCH_SIZE, 1, N_EMBD), requires_grad=True)\n",
    "cls_out = torch.cat([class_token, out], dim=1)\n",
    "print(cls_out.shape)\n",
    "\n",
    "posn_embed = nn.Parameter(torch.ones(1, NUM_PATCHES + 1, N_EMBD), requires_grad=True)\n",
    "cls_posn_out = cls_out + posn_embed\n",
    "print(cls_posn_out.shape)\n",
    "\n",
    "msa = MultiHeadAttention(N_EMBD // NUM_HEADS, is_decoder=False)\n",
    "msa_out = msa(cls_posn_out)\n",
    "print(msa_out.shape)\n",
    "\n",
    "mlp = MLP()\n",
    "mlp_out = mlp(msa_out)\n",
    "print(mlp_out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleViT(nn.Module):  # SimpleDecoder\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._token_embed = PatchEmbedding()\n",
    "        self._class_embed = nn.Parameter(torch.randn(1, 1, N_EMBD), requires_grad=True)\n",
    "        self._posn_embed = nn.Embedding(NUM_PATCHES + 1, N_EMBD)\n",
    "\n",
    "        self.blocks = nn.Sequential(*[TransformerBlock(is_decoder=False) for _ in range(NUM_BLOCKS)])\n",
    "        self.ln_f = nn.LayerNorm(N_EMBD) # final layer norm\n",
    "        self._lm_head = nn.Linear(N_EMBD, NUM_CLASSES)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        token_embed = self._token_embed(x) # B T C\n",
    "        class_token = self._class_embed.expand(BATCH_SIZE, -1, -1)\n",
    "        token_embed = torch.cat([class_token, token_embed], dim=1)\n",
    "        posn_embed = self._posn_embed(torch.arange(NUM_PATCHES + 1, device=device))  # T C\n",
    "        x = token_embed + posn_embed  # B T C\n",
    "        x = self.blocks(x)\n",
    "        # cf eqn 4 in ViT paper\n",
    "        x = x[:, 0]  # B T C -> B C\n",
    "        x = self.ln_f(x)\n",
    "        logits = self._lm_head(x)\n",
    "\n",
    "        loss = None\n",
    "        if y is not None:\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "model = SimpleViT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True\n",
    "LEARNING_RATE = 3e-3\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=LEARNING_RATE_DECAY)\n",
    "start_t = time()\n",
    "\n",
    "for i in range(NUM_EPOCHS):\n",
    "    for steps, (X, y) in enumerate(train_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        if X.size(0) != BATCH_SIZE:\n",
    "            print(f\"Skipping batch {steps} with size {X.size(0)}\")\n",
    "            continue\n",
    "\n",
    "        if not train:\n",
    "            break\n",
    "\n",
    "        logits, loss = model(X, y)\n",
    "\n",
    "        if steps % 100 == 0:\n",
    "            scheduler.step()\n",
    "            print(steps, loss.item())\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "if train:\n",
    "    torch.save(model.state_dict(), f\"bar.torch\")\n",
    "state_dict = torch.load(\"bar.torch\")\n",
    "model.load_state_dict(state_dict)\n",
    "print(f\"Took {round(time() - start_t)}s\")\n",
    "\n",
    "# inference\n",
    "pred, _ = model(images)\n",
    "probs = torch.softmax(pred, dim=1)\n",
    "label = torch.argmax(probs, dim=1)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(10, 2))\n",
    "for i in range(0, 5):\n",
    "    ax = axes[i]\n",
    "    i = i + 0\n",
    "    ax.imshow(images[i][0])\n",
    "    ax.set_title(f'Prediction: {label[i]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
